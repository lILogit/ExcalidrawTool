# ===========================================
# Hostinger Production Environment Variables
# ===========================================
# Copy this file to .env and fill in your values
# DO NOT commit .env to version control
#
# Usage:
#   cp .env.hostinger.example .env
#   nano .env  # Edit with your values
# ===========================================

# ===========================================
# Domain Configuration
# ===========================================
# Your domain name (e.g., example.com)
HOSTINGER_DOMAIN=your-domain.com

# HTTP/HTTPS ports (default: 80 and 443)
HOSTINGER_HTTP_PORT=80
HOSTINGER_HTTPS_PORT=443

# ===========================================
# SSL Certificate Paths (Let's Encrypt)
# ===========================================
# Generate using: certbot certonly --standalone -d your-domain.com
# Then copy certificates:
#   mkdir -p ssl
#   sudo cp /etc/letsencrypt/live/your-domain.com/fullchain.pem ssl/
#   sudo cp /etc/letsencrypt/live/your-domain.com/privkey.pem ssl/
#   sudo chmod 644 ssl/*.pem
SSL_CERT_PATH=./ssl/fullchain.pem
SSL_KEY_PATH=./ssl/privkey.pem

# ===========================================
# Resource Limits (adjust based on Hostinger plan)
# ===========================================
# CPU limits (1.0 = 1 CPU core)
HOSTINGER_CPU_LIMIT=1.0
HOSTINGER_CPU_RESERVE=0.25

# Memory limits (1G = 1 gigabyte)
HOSTINGER_MEMORY_LIMIT=1G
HOSTINGER_MEMORY_RESERVE=256M

# ===========================================
# Logging Configuration
# ===========================================
# Maximum log file size before rotation
HOSTINGER_LOG_MAX_SIZE=10m

# Number of log files to keep
HOSTINGER_LOG_MAX_FILES=3

# ===========================================
# AI Provider Configuration
# ===========================================
# AI Provider: 'anthropic' or 'ollama'
VITE_AI_PROVIDER=anthropic

# ===========================================
# Anthropic (Claude) Configuration
# ===========================================
# Anthropic API Key for Claude AI integration
# Get your key at: https://console.anthropic.com/
VITE_ANTHROPIC_API_KEY=sk-ant-your-key-here

# Claude model to use
# Options:
#   claude-opus-4-5-20251101   — Claude Opus 4.5 (most capable)
#   claude-sonnet-4-5-20250929 — Claude Sonnet 4.5 (balanced)
#   claude-haiku-4-5-20251001  — Claude Haiku 4.5 (fastest)
VITE_ANTHROPIC_MODEL=claude-sonnet-4-20250514

# ===========================================
# Ollama Configuration (Local LLM)
# ===========================================
# Ollama API base URL (default: http://localhost:11434)
# Uncomment if using Ollama instead of Anthropic
# VITE_OLLAMA_BASE_URL=http://localhost:11434

# Ollama model to use
# Run 'ollama list' to see available models
# Popular options: llama3.2, mistral, codellama, phi3
# VITE_OLLAMA_MODEL=llama3.2

# ===========================================
# Model Parameters (applies to all providers)
# ===========================================
# Maximum tokens in response (default: 4096)
VITE_AI_MAX_TOKENS=4096

# Temperature: Controls randomness (0.0-1.0)
# Lower = more focused, Higher = more creative
# Default: 0.7
VITE_AI_TEMPERATURE=0.7

# Top P: Nucleus sampling threshold (0.0-1.0)
# Default: 0.9
VITE_AI_TOP_P=0.9

# Top K: Limits vocabulary for each step (Ollama only)
# Default: 40
VITE_AI_TOP_K=40

# Repeat Penalty: Penalizes repetition (Ollama only)
# Default: 1.1
VITE_AI_REPEAT_PENALTY=1.1

# ===========================================
# Retry Configuration
# ===========================================
# Maximum retry attempts for AI requests when response is empty or invalid format
# Default: 3
VITE_AI_MAX_RETRIES=3

# Delay between retries in milliseconds
# Default: 1000 (1 second)
VITE_AI_RETRY_DELAY=1000

# ===========================================
# Debug & Logging Configuration
# ===========================================
# Enable AI service debug logging
# Shows detailed request/response info in console
# WARNING: May expose sensitive data in logs
VITE_AI_DEBUG=false

# Enable canvas and AI event logging
# Logs to localStorage and console for cognitive process learning
VITE_LOGGING_ENABLED=true

# Enable console output for logging service
VITE_LOG_TO_CONSOLE=false

# Maximum log entries to keep (default: 500)
VITE_MAX_LOG_ENTRIES=500

# ===========================================
# N8N Integration (if using N8N)
# ===========================================
# IMPORTANT: Use your public domain for callback URL
# Example: https://your-domain.com/api/n8n/callback
VITE_N8N_CALLBACK_URL=https://your-domain.com/api/n8n/callback

# N8N Webhook URL for sending selected canvas elements
# Example: https://your-n8n-instance.com/webhook/excalidraw
# Leave empty to disable N8N webhook feature
VITE_N8N_WEBHOOK_URL=

# N8N Webhook authentication token (optional)
# If your N8N webhook requires authentication
# VITE_N8N_WEBHOOK_TOKEN=

# Enable N8N webhook debug logging
VITE_N8N_DEBUG=false
